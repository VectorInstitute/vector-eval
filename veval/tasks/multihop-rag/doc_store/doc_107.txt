Meta has a moderation bias problem, not just a â€˜bug,â€™ thatâ€™s suppressing Palestinian voices Instagram users suspect Meta of shadowbanning content about Palestine. The platform has a history of inherent bias.

Earlier this year, Palestinian-American filmmaker Khitam Jabr posted a handful of Reels about her familyâ€™s trip to the West Bank. In the short travel vlogs, Jabr shared snippets of Palestinian culture, from eating decadent meals to dancing at her nieceâ€™s wedding.

â€œI hadnâ€™t been in a decade, so itâ€™s just like, life abroad,â€ Jabr told TechCrunch.

â€œI would get [anti-Palestine] comments,â€ she recalled. â€œAnd I couldnâ€™t respond [to them] or use my account for 24 hours. I wasnâ€™t even posting anything about the occupation. But fast forward to now and the same shitâ€™s happening.â€

In the aftermath of Hamasâ€™ attack on Israelis, Israelâ€™s retaliatory airstrikes and total blockade â€” cutting access to electricity, water and vital supplies â€” have devastated Gaza. In response to the escalating violence, Meta said that it is closely monitoring its platforms for violations and may inadvertently flag certain content, but it never intends to â€œsuppress a particular community or point of view.â€ Content praising or supporting Hamas, which governs Gaza and is designated as a terrorist organization by the United States and the European Union, is expressly forbidden on Metaâ€™s platforms.

As the humanitarian crisis in Gaza grows more dire, many social media users suspect Instagram of censoring content about the besieged Palestinian territory, even if that content doesnâ€™t support Hamas. Users have also complained that theyâ€™ve been harassed and reported for posting content about Palestine, regardless of whether or not it violates Metaâ€™s policies. Jabr, for example, suspects that Instagram restricted her for 24 hours because other users reported her Palestine travel videos. Most recently, Instagram users accused Meta of â€œshadowbanningâ€ their Stories about Palestine.

Itâ€™s the latest in a lengthy history of incidents on Meta platforms that reflect an inherent bias against Palestinian users in its processes, as documented by years of complaints from both inside and outside the company. The company may not intentionally suppress specific communities, but its moderation practices often disproportionately affect Palestinian users.

For instance, Meta struggles to navigate the cultural and linguistic nuances of Arabic, a language with over 25 dialects, and has been criticized for neglecting to adequately diversify its language resources. The companyâ€™s black-and-white policies often preclude it from effectively moderating any nuanced topic, like content that discusses violence without condoning it. Advocacy groups have also raised concerns that Metaâ€™s partnerships with government agencies, such as the Israeli Cyber Unit, politically influence the platformâ€™s policy decisions.

During the last violent outbreak between Hamas and Israel in 2021, a report commissioned by Meta and conducted by a third party concluded that the companyâ€™s actions had an â€œadverse human rights impactâ€ on Palestinian usersâ€™ right to freedom of expression and political participation.

Meta communications director Andy Stone declined to comment on the record, and pointed TechCrunch to Metaâ€™s newsroom post about the conflict, which was updated on Oct. 18 with a statement addressing the shadowbanning claims.

â€œOur policies are designed to keep people safe on our apps while giving everyone a voice,â€ the post stated. â€œWe apply these policies equally around the world and there is no truth to the suggestion that we are deliberately suppressing voice â€¦ We can make errors and that is why there is an appeals process for people to tell us when they think we have made the wrong decision, so we can look into it.â€

The belief that Meta shadowbans, or limits the visibility of, content about Palestine is not new. In an Instagram Story last year, supermodel and activist Bella Hadid, who is of Palestinian descent, alleged that Instagram â€œdisabledâ€ her from posting content on her Story â€œpretty much only when it is Palestine based.â€ She said she gets â€œimmediately shadowbannedâ€ when she posts about Palestine, and her Story views drop by â€œalmost 1 million.â€

As soon as Kehlani got super vocal and changed her profile picture to â€œi stand with Palestineâ€ she got shadowbanned.

Just as they did to Bella Hadid. The propaganda is insane.

THEY TRY TO SILENCE US. DONâ€™T STOP!!

FREE PALESTINE. ğŸ‡µğŸ‡¸ğŸ‡µğŸ‡¸ pic.twitter.com/4lUvZsUbiA â€” Sabby Targaryen ğŸ‰ (@whoisitbad) October 14, 2023

Meta blamed technical errors for the removal of posts about Palestine during the 2021 conflict. When reached for comment about these recent claims of shadowbanning, a representative for the company pointed TechCrunch to a Threads post by Stone.

â€œWe identified a bug impacting all Stories that re-shared Reels and Feed posts, meaning they werenâ€™t showing up properly in peopleâ€™s Stories tray, leading to significantly reduced reach,â€ Stone said. â€œThis bug affected accounts equally around the globe and had nothing to do with the subject matter of the content â€” and we fixed it as quickly as possible.â€

But many are frustrated that Meta continues to disproportionately suppress Palestinian voices. Leen Al Saadi, a Palestinian journalist currently based in Jordan and host of the podcast â€œPreserving Palestine,â€ said she is used to â€œconstantly being censored.â€ Her Instagram account was restricted last year after she posted a trailer for the podcastâ€™s first episode, which discussed a documentary about Palestinian street art under occupation.

â€œPalestinians are currently undergoing two wars,â€ Al Saadi said. â€œThe first is with their legal occupier. The second war is with the entire Western media landscape, and when I say the entire landscape, I mean social media.â€

Metaâ€™s alleged shadowbanning

Instagram users accuse Meta of suppressing more than just Stories related to Palestine.

Creators say engagement on their posts tanked specifically after they publicly condemned Israelâ€™s response to the Hamas attack as excessively violent. Some, like Jabr, say they were restricted from posting or going live, while others say Instagram flagged their content as â€œsensitive,â€ limiting its reach. Users also allege their posts were flagged as â€œinappropriateâ€ and removed, even if the content adhered to Instagramâ€™s Community Guidelines.

Metaâ€™s representative didnâ€™t address the other accusations of censorship beyond just Story visibility and did not respond to TechCrunchâ€™s follow-up questions. When asked for comment, Stone directed TechCrunch to Metaâ€™s updated newsroom post, which said Meta identified and fixed a â€œbugâ€ that prevented users from going live.

â€œThis was also a global issue that was fixed within a few hours. We understand people rely on these tools and weâ€™re sorry to anyone who felt the impact of these issues,â€ the post stated.

Itâ€™s unclear if this â€œbugâ€ impacted accounts posting content unrelated to Gaza. Instagram users have posted screenshots showing that Stories about Palestine have received significantly fewer views than other Stories posted on the same day, and allege that their view counts went back up when they posted content unrelated to the conflict.

ofc IGâ€™s hiding my stories about Palestine, yâ€™all see the difference? lmaoaoaoao pic.twitter.com/1iYIIKBhtN â€” à¼’ï¸ (@arxbprince) October 15, 2023

A user based in Egypt, who asked to stay anonymous for fear of harassment, said her posts usually get around 300 views, but when she started posting pro-Palestine content after the Hamas attack earlier this month, her stories would only get one to two views.

â€œIt happened to all my friends, too,â€ she continued. â€œThen we noticed that posting a random pic would get higher views. So by posting a random pic, then a pro-Palestine post, would increase the views.â€

Another Instagram user based in the United Kingdom, who also asked to stay anonymous out of fear of harassment, said that his view count returned to normal when he posted a cat photo.

â€œMy stories went from 100s of views to zero or a handful,â€ he said. â€œIâ€™ve had to post intermittent non-Gaza content in order to â€˜releaseâ€™ my stories to be viewed again.â€

It isnâ€™t just Stories. The Arab Center for Social Media Advancement (7amleh), which documents cases of Palestinian digital rights violations and works directly with social media companies to appeal violations, told TechCrunch it has received reports of Instagram inconsistently filtering comments containing the Palestinian flag emoji. Users report that Instagram has flagged comments containing the emoji as â€œpotentially offensive,â€ hiding the comment.

Meta initially did not respond to follow-up requests for comment. When asked for comment, Stone pointed TechCrunch to Metaâ€™s updated newsroom post, which did not directly address issues related to comments containing the Palestinian flag.

The organization has also received countless reports of Meta flagging and restricting Arabic content, even if itâ€™s posted by news outlets. Jalal Abukhater, 7amlehâ€™s advocacy manager, said that the organization has documented multiple cases of journalists on Instagram reporting the same news in Arabic, Hebrew and English, but only getting flagged for their Arabic content.

â€œItâ€™s literally journalistic content, but the same wording in Hebrew and English does not get restricted,â€ Abukhater said. â€œAs if thereâ€™s better moderation for those languages, and more careless moderation for Arabic content.â€

Stone declined to comment on allegations of Meta disproportionately flagging Arabic news content, instead directing TechCrunch to the updated newsroom post â€” which did not directly address the allegations.

And as the Intercept reported, Instagram and Facebook are flagging images of the al-Ahli Hospital, claiming that the content violates Metaâ€™s Community Guidelines on nudity or sexual activity.

The Community Guidelines are enforced inconsistently, particularly when it comes to content related to Palestine. Al Saadi recently tried to report a comment that said she should be â€œrapedâ€ and â€œburned aliveâ€ â€” left in response to her comment on a CNN post about the conflict â€” but in screenshots reviewed by TechCrunch, Instagram said that it didnâ€™t violate the platformâ€™s Community Guidelines against violence or dangerous organizations.

â€œThe restrictions on content, especially the content that relates to Palestine, is heavily politicized,â€ Abukhater said. â€œIt feeds into the bias against Palestinian narrative genuinely. It really takes the balance against Palestinians in a situation where thereâ€™s a huge asymmetry of power.â€

A history of suppression

Content about Palestine is disproportionately scrutinized, as demonstrated during the last severe violent outbreak between Hamas and Israel two years ago. Amid the violence following the May 2021 court ruling to evict Palestinian families from Sheikh Jarrah, a neighborhood in occupied East Jerusalem, users across Facebook and Instagram accused Meta of taking down posts and suspending accounts that voiced support for Palestinians.

The digital rights nonprofit Electronic Frontier Foundation (EFF) described Metaâ€™s actions in 2021 as â€œsystemic censorship of Palestinian voices.â€ In its 2022 report of Palestinian digital rights, 7amleh said that Meta is â€œstill the most restricting companyâ€ compared to other social media giants in the extent of its moderation of the Palestinian digital space.

Meta forbids support of terrorist organizations, like most social media companies based in the U.S., but struggles to moderate content around it, from user discourse to journalistic updates. This policy, along with the companyâ€™s partnership with Israel to monitor posts that incite violence, complicates things for Palestinians living under Hamasâ€™ governance. As EFF points out, something as simple as Hamasâ€™ flag in the background of an image can result in a strike.

Jillian York, the director for international freedom of expression for EFF, blames automation and decisions made by â€œminimally trained humansâ€ for the inconsistency. Metaâ€™s zero tolerance policy and imprecise enforcement often suppress content from or about conflict zones, she said. The siteâ€™s moderation issues have negatively affected multiple non-English speaking regions, including Libya, Syria and Ukraine.

â€œThese rules can prevent people from sharing documentation of human rights violations, documentation of war crimes, even just news about whatâ€™s happening on the ground,â€ York continued. â€œAnd so I think that is what is the most problematic right now about that particular rule, and the way that itâ€™s enforced.â€

Over the 13 days leading up to the ceasefire between Hamas and Israel, 7amleh documented more than 500 reports of Palestinian â€œdigital rights violations,â€ including the removal and restriction of content, hashtags and accounts related to the conflict.

Meta blamed some of the instances of perceived censorship to technical issues, like one that prevented users in Palestine and Colombia from posting Instagram Stories. It attributed others to human error, like blocking the hashtag for Al-Aqsa Mosque, the holy site where Israeli police clashed with Ramadan worshippers, because it was mistaken for a terrorist organization. The company also blocked journalists in Gaza from WhatsApp without explanation.

The same month, a group of Facebook employees filed internal complaints accusing the company of bias against Arab and Muslim users. In internal posts obtained by BuzzFeed News, an employee attributed the bias to â€œyears and years of implementing policies that just donâ€™t scale globally.â€

At the recommendation of its Oversight Board, Meta conducted a third-party due diligence report about the platformâ€™s moderation during the May 2021 conflict. The report found that Arabic content was flagged as potentially violating at significantly higher rates than Hebrew content was, and was more likely to be erroneously removed. The report noted that Metaâ€™s moderation system may not be as precise for Arabic content as it was for Hebrew content, because the latter is a â€œmore standardized language,â€ and suggested that reviewers may lack the linguistic and cultural competence to understand less common Arabic dialects like Palestinian Arabic.

Has anything improved?

Meta committed to implementing policy changes based on the reportâ€™s recommendations, such as updating its keywords associated with dangerous organizations, disclosing government requests to remove content and launching a hostile speech classifier for Hebrew content. Abukhater added that Meta has improved its response to harassment, at least in comparison to other social media platforms like X (formerly Twitter). Although harassment and abuse are still rampant on Instagram and Facebook, he said, the company has been responsive to suspending accounts with patterns of targeting other users.

The company has also made more contact with regional Palestinian organizations since 2021, York added, but itâ€™s been slow to implement recommendations from EFF and other advocacy groups. Itâ€™s â€œvery clearâ€ that Meta is not putting the same resources behind Arabic and other non-English languages, York said, compared to the attention Meta gives to countries that have the most regulatory pressure. Moderation of English and other European languages tends to be more comprehensive, for example, because the EU enforces the Digital Services Act.

In Metaâ€™s response to the report, Miranda Sissons, the companyâ€™s director of human rights, said that Meta was â€œassessing the feasibilityâ€ of reviewing Arabic content by dialect. Sissons said that the company has â€œlarge and diverse teamsâ€ who understand â€œlocal cultural context across the region,â€ including in Palestine. Responding to the escalating violence earlier this month, Meta stated that it established a â€œspecial operations centerâ€ staffed with fluent Hebrew and Arabic speakers to closely monitor and respond to violating content.

Despite Metaâ€™s apparent efforts to diversify its language resources, Arabic is still disproportionately flagged as violating â€” like in the case of journalists reporting news in multiple languages.

â€œThe balance of power is very fixed, in reality, between Israelis and Palestinians,â€ Abukhater said. â€œAnd this is something that today is reflected heavily on platforms like Meta, even though they have human rights teams releasing reports and trying to improve upon their policies. Whenever an escalation like the one weâ€™re experiencing now happens, things just go back to zero.â€

And at times, Metaâ€™s Arabic translations are completely inaccurate. This week, multiple Instagram users raised concerns over the platform mistranslating the relatively common Arabic phrase â€œAlhamdulillah,â€ or â€œPraise be to God.â€ In screen recordings posted online, users found that if they included â€œPalestinianâ€ and the corresponding flag emoji in their Instagram bio along with the Arabic phrase, Instagram automatically translated their bio to â€œPalestinian terrorists â€“ Praise be to Allahâ€ or â€œPraise be to God, Palestinian terrorists are fighting for their freedom.â€ When users removed â€œPalestinianâ€ and the flag emoji, Instagram translated the Arabic phrase to â€œThank God.â€ Instagram users complained that the offensive mistranslation was active for hours before Meta appeared to correct it.

Shayaan Khan, a TikTok creator who posted a viral video about the mistranslation, told TechCrunch that Metaâ€™s lack of cultural competence isnâ€™t just offensive, itâ€™s dangerous. He said that the â€œglitchâ€ can fuel Islamophobic and racist rhetoric, which has already been exacerbated by the war in Gaza. Khan pointed to the fatal stabbing of Wadea Al-Fayoume, a Palestinian-American child whose death is being investigated as a hate crime.

Meta did not respond to TechCrunchâ€™s request for comment about the mistranslation. Abukhater said that Meta told 7amleh that a â€œbugâ€ caused the mistranslation. In a statement to 404 Media, a Meta spokesperson said that the issue had been fixed.

â€œWe fixed a problem that briefly caused inappropriate Arabic translations in some of our products,â€ the statement said, â€œWe sincerely apologize that this happened.â€

As the war continues, social media users have tried to find ways around the alleged shadowbanning on Instagram. Supposed loopholes include misspelling certain words, like â€œp@lestineâ€ instead of â€œPalestine,â€ in hopes of bypassing any content filters. Users also share information about Gaza in text superimposed over unrelated images, like a cat photo, so it wonâ€™t be flagged as graphic or violent content. Creators have tried to include an emoji of the Israeli flag or tag their posts and Stories with #istandwithisrael, even if they donâ€™t support the Israeli government, in hopes of gaming engagement.

Al Saadi said that her frustration with Meta is common among Palestinians, both in occupied territories and across the diaspora.

â€œAll weâ€™re asking for is to give us the exact same rights,â€ she said. â€œWeâ€™re not asking for more. Weâ€™re literally just asking Meta, Instagram, every single broadcast channel, every single media outlet, to just give us the respect that we deserve.â€

Dominic-Madori Davis contributed to this storyâ€™s reporting.