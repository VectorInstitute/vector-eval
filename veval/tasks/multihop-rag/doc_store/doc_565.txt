After marathon â€˜finalâ€™ talks which stretched to almost three days European Union lawmakers have tonight clinched a political deal on a risk-based framework for regulating artificial intelligence. The file was originally proposed back in April 2021 but itâ€™s taken months of tricky three-way negotiations to get a deal over the line. The development means a pan-EU AI law is definitively on the way.

Giving a triumphant but exhausted press conference in the small hours of Friday night/Saturday morning local time key representatives for the European Parliament, Council and the Commission â€” the blocâ€™s co-legislators â€” hailed the agreement as hard fought, a milestone achievement and historic, respectively.

Taking to X to tweet the news, the EUâ€™s president, Ursula von der Leyen â€” who made delivering a regulation to promote â€œtrustworthyâ€ AI a key priority of her term when she took up the post in late 2019 â€” also lauded the political agreement as a â€œglobal firstâ€.

The ğŸ‡ªğŸ‡º AI Act is a global first. A unique legal framework for the development of AI you can trust. And for the safety and fundamental rights of people and businesses. A commitment we took in our political guidelines â€“ and we delivered. I welcome today's political agreement. â€” Ursula von der Leyen (@vonderleyen) December 8, 2023

Prohibitions

Full details of whatâ€™s been agreed wonâ€™t be entirely confirmed until a final text is compiled and made public, which may take some weeks. But a press release put out by the European Parliament confirms the deal reached with the Council includes a total prohibition on the use of AI for:

biometric categorisation systems that use sensitive characteristics (e.g. political, religious, philosophical beliefs, sexual orientation, race);

untargeted scraping of facial images from the internet or CCTV footage to create facial recognition databases;

emotion recognition in the workplace and educational institutions;

social scoring based on social behaviour or personal characteristics;

AI systems that manipulate human behaviour to circumvent their free will;

AI used to exploit the vulnerabilities of people (due to their age, disability, social or economic situation).

The use of remote biometric identification technology in public places by law enforcement has not been completely banned â€” but the parliament said negotiators had agreed on a series of safeguards and narrow exceptions to limit use of technologies such as facial recognition. This includes a requirement for prior judicial authorisation â€” and with uses limited to a â€œstrictly definedâ€ lists of crime.

Retrospective (non-real-time) use of remote biometric ID AIs will be limited to â€œthe targeted search of a person convicted or suspected of having committed a serious crimeâ€. While real-time use of this intrusive AI tech will be limited in time and location, and can only be used for the following purposes:

targeted searches of victims (abduction, trafficking, sexual exploitation),

prevention of a specific and present terrorist threat, or

the localisation or identification of a person suspected of having committed one of the specific crimes mentioned in the regulation (e.g. terrorism, trafficking, sexual exploitation, murder, kidnapping, rape, armed robbery, participation in a criminal organisation, environmental crime).

The Councilâ€™s press release on the deal emphasizes that the provisional agreement â€œclarifies that the regulation does not apply to areas outside the scope of EU law and should not, in any case, affect member statesâ€™ competences in national security or any entity entrusted with tasks in this areaâ€. It also confirms the AI act will not apply to systems exclusively for military or defence purposes.

â€œSimilarly, the agreement provides that the regulation would not apply to AI systems used for the sole purpose of research and innovation, or for people using AI for non-professional reasons,â€ the Council added.

Civil society groups have reacted sceptically â€” raising concerns the agreed limitations on state agenciesâ€™ use of biometric identification technologies will not go far enough to safeguard human rights. Digital rights group EDRi, which was among those pushing for a full ban on remote biometrics, said that whilst the deal contains â€œsome limited gains for human rightsâ€, it looks like â€œa shell of the AI law Europe really needsâ€.

Real-time public facial recognition (RBI): disappointingly, but not surprisingly, member states resisted a full ban. The Parliament fought hard to narrow exceptions and add more safeguards, but it doesn't look like it will be enough to stop widespread biometric mass surveillance; â€” Ella Jakubowska (@ellajakubowska1) December 9, 2023

Rules for â€˜high riskâ€™ AIs, and general purpose AIs

The package agreed also includes obligations for AI systems that are classified as â€œhigh riskâ€ owing to having â€œsignificant potential harm to health, safety, fundamental rights, environment, democracy and the rule of lawâ€.

â€œMEPs successfully managed to include a mandatory fundamental rights impact assessment, among other requirements, applicable also to the insurance and banking sectors. AI systems used to influence the outcome of elections and voter behaviour, are also classified as high-risk,â€ the parliament wrote. â€œCitizens will have a right to launch complaints about AI systems and receive explanations about decisions based on high-risk AI systems that impact their rights.â€

There was also agreement on a â€œtwo-tierâ€ system of guardrails to be applied to â€œgeneralâ€ AI systems, such as the so-called foundational models underpinning the viral boom in generative AI applications like ChatGPT.

As we reported earlier, the deal reached on foundational models/general purpose AIs (GPAIs) includes some transparency requirements for what co-legislators referred to as â€œlow tierâ€ AIs â€” meaning model makers must draw up technical documentation and produce (and publish) detailed summaries about the content used for training in order to support compliance with EU copyright law. For â€œhigh-impactâ€ GPAIs (defined as the cumulative amount of compute used for their training measured in floating point operations is greater than 10^25) with so-called â€œsystemic riskâ€ there are more stringent obligations.

â€œIf these models meet certain criteria they will have to conduct model evaluations, assess and mitigate systemic risks, conduct adversarial testing, report to the Commission on serious incidents, ensure cybersecurity and report on their energy efficiency,â€ the parliament wrote. â€œMEPs also insisted that, until harmonised EU standards are published, GPAIs with systemic risk may rely on codes of practice to comply with the regulation.â€

The Commission has been working with industry on a stop-gap AI Pact for some months â€” and it confirmed today this is intended to plug the practice gap until the AI Act comes into force.

While foundational models/GPAIs that have been commercialized face regulation under the Act, R&D is not intended to be in scope of the law â€” and fully open sourced models will have lighter regulatory requirements than closed source, per todayâ€™s pronouncements.

The package agreed also promotes regulatory sandboxes and real-world-testing being established by national authorities to support startups and SMEs to develop and train AIs before placement on the market.

Penalties and entry into force

Penalties for non-compliance can lead to fines ranging from â‚¬35 million or 7% of global turnover to â‚¬7.5 million or 1.5 % of turnover, depending on the infringement and size of the company, per the parliament.

The Councilâ€™s PR further stipulates that the higher sanction (7%) would apply for violations of the banned AI applications, while penalties of 1.5% would be levied for the supply of incorrect information. Additionally, it says sanctions of 3% could be imposed for violations of other AI Act obligations but also notes that the provisional agreement allows for â€œmore proportionate capsâ€ on administrative fines for SMEs and start-ups in case of infringements. So there looks to be some scope for AI startups to face smaller penalties for infringements than AI giants may invite.

The deal agreed today also allows for a phased entry into force after the law is adopted â€” with six months allowed until rules on prohibited use cases kick in; 12 months for transparency and governance requirements; and 24 months for all other requirements. So the full force of the EUâ€™s AI Act may not be felt until 2026.

Carme Artigas, Spainâ€™s secretary of state for digital and AI issues, who led the Councilâ€™s negotiations on the file as the country has held the rotating Council presidency since the summer, hailed the agreement on the heavily contested file as â€œthe biggest milestone in the history of digital information in Europeâ€; both for the blocâ€™s single digital market â€” but also, she suggested, â€œfor the worldâ€.

â€œWe have achieved the first international regulation for artificial intelligence in the world,â€ she announced during a post-midnight press conference to confirm the political agreement, adding: â€œWe feel very proud.â€

The law will support European developers, startups and future scale-ups by giving them â€œlegal certainty with technical certaintyâ€, she predicted.

Speaking on behalf of the European Parliament, co-rapporteurs DragoÈ™ Tudorache and Brando Benifei said their objective had been to deliver AI legislation that would ensure the ecosystem developed with a â€œhuman centric approachâ€ which respects fundamental rights and European values.

Their assessment of the outcome was equally upbeat â€” citing the inclusion in the agreed text of a total ban on the use of AI for predictive policing and for biometric categorization as major wins.

â€œFinally we got in the right track, defending fundamental rights to the necessity that is there for our democracies to endure such incredible changes,â€ said Benifei, who just a few weeks ago was sounding doubtful a deal could be found. â€œWe are the first ones in the world to have a horizontal legislation that has this direction on fundamental rights, that supports the development of AI in our continent, and that is up to date to the frontier of the artificial intelligence with the most powerful models under clear obligation. So I think we delivered.â€

â€œWe have always been questioned whether there is enough protection, whether there is enough stimulant for innovation in this text, and I can say, this balance is there,â€ added Tudorache. â€œWe have safeguards, we have all the provisions that we need, the redress that we need in giving trust to our citizens in the interaction with AI, in the products in the services that they will interact with from now on.

â€œWe now have to use this blueprint to seek now global convergence because this is a global challenge for everyone. And I think that with the work that weâ€™ve done, as difficult as it was â€” and it was difficult, this was a marathon negotiation by all standards, looking at all precedents so far â€” but I think we delivered.â€

The EUâ€™s internal market commissioner, Thierry Breton, also chipped in with his two euro-cents â€” describing the agreement clinched a little before midnight Brusselsâ€™ time as â€œhistoricâ€. â€œIt is a full package. It is a complete deal. And this is why we spent so much time,â€ he intoned. â€œThis is balancing user safety, innovation for startups, while also respectingâ€¦ our fundamental rights and our European values.â€

Clear road ahead?

Despite the EU very visibly patting itself on the back tonight on securing a deal on â€˜world-firstâ€™ AI rules, itâ€™s not quite yet the end of the road for the blocâ€™s lawmaking process as there are still some formal steps to go â€” not least the final text will face votes in the parliament and the Council to adopt it. But given how much division and disagreement there has been over how (or even whether) to regulate AI the biggest obstacles have been dismantled with this political deal and the path to passing the EU AI Act in the coming months looks clear.

The Commission is certainly projecting confidence. Per Breton, work to implement the agreement starts immediately with the set up of an AI Office within the EUâ€™s executive â€” which will have the job of coordinating with the Member State oversight bodies that will need to enforce the rules on AI firms; and overseeing the most advanced AI models, including by contributing to fostering standards and testing practices. A scientific panel of independent experts will be appointed to advise the AI Office about GPAI models. â€œWe will welcome new colleaguesâ€¦ a lot of them,â€ said Breton. â€œWe will work â€” starting tomorrow â€” to get ready.â€

Opposition to the inclusion in the AI package of tiered rules for general purpose AIs has been led, in recent weeks, by France â€” and French AI startup Mistral, which had been lobbying for a total carve out from obligations for foundational models/GPAIs. In the event the deal agreed by the Spanish presidency does contain some obligations for GPAIs and foundation models. So itâ€™s not the total carve out Mistral and its lobbyists have been pushing for.

Responding to news of the political deal last night, Franceâ€™s digital ministerâ€™s office put out a statement attributed to Jean-NoÃ«l Barrot which said (translated from French using AI): â€œWe will be carefully analyzing the compromise reached today, and in the coming weeks we will ensure that the text preserves Europeâ€™s ability to develop its own artificial intelligence technologies, and safeguards its strategic autonomy.â€

It remains unclear how much of a carve out Mistralâ€™s business might enjoy under the deal agreed. Asked about this during the press conference, Artigas suggested the French AI startup would â€” once commercialized â€” be likely to fit in the â€œlow tierâ€ for GPAIs, meaning it would have only limited transparency obligations, since she said it does not hit the high capacity compute threshold triggering the systemic risk obligations (as she said itâ€™s using whatâ€™s thought to be 10^23 of compute, not 10^25).

However, as Mistral is currently still in an R&D and pre-training phase for their models, she said they would be excluded from even the low tier compliance requirements.

This report was updated to include the response from the French digital ministry; link to the Councilâ€™s PR; and with additional details from the presser â€” including remarks about how the law might apply to Mistral. We also added details on civil societyâ€™s response